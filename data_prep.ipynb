{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import math,random\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "def load_audio_files(path: str, label:str):\n",
    "\n",
    "    dataset = []\n",
    "    walker = sorted(str(p) for p in Path(path).glob(f'*.wav'))\n",
    "\n",
    "    for i, file_path in enumerate(walker):\n",
    "        path, filename = os.path.split(file_path)\n",
    "    \n",
    "        # Load audio\n",
    "        #waveform, sample_rate = torchaudio.load(file_path)\n",
    "        dataset.append([file_path, label])\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "trainset_music_good = load_audio_files('./data/good', 'good')\n",
    "trainset_music_bad = load_audio_files('./data/bad', 'bad')\n",
    "trainset_music=trainset_music_good+trainset_music_bad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def open_file(audio_file):\n",
    "    waveform, sample_rate = torchaudio.load(audio_file)\n",
    "    return (waveform, sample_rate)\n",
    "\n",
    "#convert stereo to mono to save resources\n",
    "def toMono(audio):\n",
    "    waveform,s=audio\n",
    "    return (waveform[:1,:],s)\n",
    "\n",
    "def pad_trunc(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "\n",
    "    if (sig_len > max_len):\n",
    "        # Truncate the signal to the given length\n",
    "        sig = sig[:,:max_len]\n",
    "\n",
    "    elif (sig_len < max_len):\n",
    "        # Length of padding to add at the beginning and end of the signal\n",
    "        pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "        pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "        # Pad with 0s\n",
    "        pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "        pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "        sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "        \n",
    "    return (sig, sr)\n",
    "\n",
    "def time_shift(aud, shift_limit):\n",
    "    sig,sr = aud\n",
    "    _, sig_len = sig.shape\n",
    "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "    return (sig.roll(shift_amt), sr)\n",
    "\n",
    "def pitch_shift(aud, shift_limit):\n",
    "    sig,sr = aud\n",
    "    shift_amt = int(random.random() * shift_limit)\n",
    "    sig=transforms.PitchShift(sample_rate=sr, n_steps=shift_amt)(sig)\n",
    "    return (sig,sr)\n",
    "def speed_shift(aud, shift_limit):\n",
    "    sig,sr = aud\n",
    "    shift_amt = int(random.random() * shift_limit)\n",
    "    sig=transforms.Speed(sig,sr, shift_amt)\n",
    "    return (sig,sr)\n",
    "\n",
    "def data_augment(aud):\n",
    "    aud=pitch_shift(aud,4)\n",
    "    aud=time_shift(aud,0.1)\n",
    "    return aud\n",
    "def stretch(spec):\n",
    "    rate=int(random.random()*0.2)+0.9\n",
    "    spec=transforms.TimeStretch(n_freq=512,fixed_rate=rate)(spec)\n",
    "    return spec\n",
    "\n",
    "def spectro_gram(aud, n_mels=512, n_fft=4096, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "\n",
    "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "    # Convert to decibels\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)\n",
    "\n",
    "\n",
    "for i in range(0,2):\n",
    "    for data in trainset_music:\n",
    "        filename=data[0]\n",
    "        \n",
    "        wv=open_file(filename)\n",
    "        wv=toMono(wv)\n",
    "        wv=pad_trunc(wv,60000*2)\n",
    "        if i>0:\n",
    "            wv=data_augment(wv)\n",
    "        spec=spectro_gram(wv)\n",
    "        spec=spec[0].detach().numpy()\n",
    "\n",
    "        label=data[1]\n",
    "\n",
    "        _,filename=os.path.split(filename)\n",
    "        filename,_=os.path.splitext(filename)\n",
    "\n",
    "        plt.imsave(f'./data/spectrograms/{label}/{filename}_{i}.png',spec,cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
